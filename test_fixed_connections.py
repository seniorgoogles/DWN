"""
Test that fixed connections work correctly with LUTLayer
"""
import torch
import torch.nn as nn
import torch_dwn as dwn

print("=" * 70)
print("üß™ TESTING FIXED CONNECTIONS WITH LUTLAYER")
print("=" * 70)

# ============================================================================
# TEST 1: Create LUTLayer with fixed connections
# ============================================================================
print("\n" + "=" * 70)
print("TEST 1: Creating LUTLayer with Fixed Connections")
print("=" * 70)

# Define a specific connection pattern
input_size = 128
output_size = 10
n = 6

# Create fixed mapping: each neuron connects to specific inputs
# Neuron 0 ‚Üí inputs [0, 1, 2, 3, 4, 5]
# Neuron 1 ‚Üí inputs [10, 20, 30, 40, 50, 60]
# etc.
fixed_mapping = torch.zeros(output_size, n, dtype=torch.int32)
for i in range(output_size):
    for j in range(n):
        fixed_mapping[i, j] = (i * 10 + j * 10) % input_size

print(f"Fixed mapping shape: {fixed_mapping.shape}")
print(f"Fixed mapping dtype: {fixed_mapping.dtype}")
print(f"\nExample connections:")
for i in range(min(3, output_size)):
    print(f"  Neuron {i}: {fixed_mapping[i].tolist()}")

# Create LUTLayer with fixed connections
try:
    lut_layer = dwn.LUTLayer(
        input_size=input_size,
        output_size=output_size,
        n=n,
        mapping=fixed_mapping  # Pass tensor directly
    )
    print("\n‚úÖ LUTLayer created successfully with fixed connections")
except Exception as e:
    print(f"\n‚ùå FAILED to create LUTLayer: {e}")
    import traceback
    traceback.print_exc()
    exit(1)

# ============================================================================
# TEST 2: Verify mapping is stored correctly and non-trainable
# ============================================================================
print("\n" + "=" * 70)
print("TEST 2: Verify Mapping Properties")
print("=" * 70)

# Check if mapping is a parameter
if isinstance(lut_layer.mapping, nn.Parameter):
    print("‚úÖ Mapping is stored as nn.Parameter")
else:
    print("‚ùå Mapping is NOT stored as nn.Parameter")
    exit(1)

# Check if mapping is non-trainable
if not lut_layer.mapping.requires_grad:
    print("‚úÖ Mapping is non-trainable (requires_grad=False)")
else:
    print("‚ùå WARNING: Mapping is trainable (requires_grad=True)")

# Verify the values are preserved
if torch.equal(lut_layer.mapping, fixed_mapping):
    print("‚úÖ Mapping values are preserved exactly")
else:
    print("‚ùå Mapping values were changed!")
    exit(1)

# ============================================================================
# TEST 3: Check all trainable parameters
# ============================================================================
print("\n" + "=" * 70)
print("TEST 3: Trainable Parameters")
print("=" * 70)

trainable_params = []
non_trainable_params = []

for name, param in lut_layer.named_parameters():
    if param.requires_grad:
        trainable_params.append(name)
    else:
        non_trainable_params.append(name)

print("Trainable parameters:")
for name in trainable_params:
    print(f"  ‚úì {name}")

print("\nNon-trainable parameters (fixed):")
for name in non_trainable_params:
    print(f"  üîí {name}")

if 'mapping' in non_trainable_params:
    print("\n‚úÖ Mapping is correctly marked as non-trainable")
else:
    print("\n‚ùå WARNING: Mapping not in non-trainable list")

# ============================================================================
# TEST 4: Forward pass (requires CUDA)
# ============================================================================
print("\n" + "=" * 70)
print("TEST 4: Forward Pass")
print("=" * 70)

if torch.cuda.is_available():
    try:
        # Move to CUDA
        lut_layer = lut_layer.cuda()

        # Create test input
        batch_size = 4
        test_input = torch.randn(batch_size, input_size).cuda()

        print(f"Input shape: {test_input.shape}")

        # Forward pass
        output = lut_layer(test_input)

        print(f"Output shape: {output.shape}")
        print(f"‚úÖ Forward pass successful")

        # Verify output shape
        if output.shape == (batch_size, output_size):
            print(f"‚úÖ Output shape is correct: {output.shape}")
        else:
            print(f"‚ùå Output shape is wrong: {output.shape}, expected: ({batch_size}, {output_size})")
            exit(1)

    except Exception as e:
        print(f"‚ùå Forward pass failed: {e}")
        import traceback
        traceback.print_exc()
        exit(1)
else:
    print("‚ö†Ô∏è  CUDA not available, skipping forward pass test")

# ============================================================================
# TEST 5: Verify connections don't change during training
# ============================================================================
print("\n" + "=" * 70)
print("TEST 5: Verify Connections Stay Fixed During Training")
print("=" * 70)

if torch.cuda.is_available():
    try:
        # Save original mapping
        original_mapping = lut_layer.mapping.clone()

        # Create a simple training setup
        lut_layer.train()
        optimizer = torch.optim.Adam(lut_layer.parameters(), lr=0.01)

        # Do a few training steps
        for step in range(5):
            # Random input and target
            x = torch.randn(8, input_size).cuda()
            target = torch.randn(8, output_size).cuda()

            # Forward pass
            output = lut_layer(x)

            # Loss and backward
            loss = nn.MSELoss()(output, target)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

        print(f"Completed 5 training steps")

        # Check if mapping changed
        if torch.equal(lut_layer.mapping, original_mapping):
            print("‚úÖ Mapping stayed FIXED during training (unchanged)")
        else:
            diff = (lut_layer.mapping != original_mapping).sum().item()
            print(f"‚ùå WARNING: Mapping changed! {diff} values different")
            exit(1)

    except Exception as e:
        print(f"‚ùå Training test failed: {e}")
        import traceback
        traceback.print_exc()
        exit(1)
else:
    print("‚ö†Ô∏è  CUDA not available, skipping training test")

# ============================================================================
# TEST 6: Build a full model like your use case
# ============================================================================
print("\n" + "=" * 70)
print("TEST 6: Full Model with Fixed Connections (Your Use Case)")
print("=" * 70)

# Simulate your pruned connections
connections = [
    {
        'in_features': 128,
        'out_features': 64,
        'connections_per_neuron': [
            {'neuron_idx': i, 'active_input_indices': list(range(i*2, i*2 + 6)), 'num_connections': 6}
            for i in range(64)
        ]
    },
    {
        'in_features': 64,
        'out_features': 10,
        'connections_per_neuron': [
            {'neuron_idx': i, 'active_input_indices': list(range(i*6, i*6 + 6)), 'num_connections': 6}
            for i in range(10)
        ]
    }
]

def create_fixed_mapping_from_connections(connection_info):
    """Same as your function"""
    out_features = connection_info['out_features']
    n_inputs = connection_info['connections_per_neuron'][0]['num_connections']

    mapping = torch.zeros(out_features, n_inputs, dtype=torch.int32)

    for neuron_info in connection_info['connections_per_neuron']:
        neuron_idx = neuron_info['neuron_idx']
        active_indices = neuron_info['active_input_indices']

        for i, idx in enumerate(active_indices):
            mapping[neuron_idx, i] = idx

    return mapping

# Create mappings
mappings = []
for conn_info in connections:
    mapping = create_fixed_mapping_from_connections(conn_info)
    mappings.append(mapping)
    print(f"Created mapping: {mapping.shape}")

# Build model
try:
    lut_layer1 = dwn.LUTLayer(
        connections[0]['in_features'],
        connections[0]['out_features'],
        n=6,
        mapping=mappings[0]
    )

    lut_layer2 = dwn.LUTLayer(
        connections[1]['in_features'],
        connections[1]['out_features'],
        n=6,
        mapping=mappings[1]
    )

    model = nn.Sequential(
        lut_layer1,
        nn.ReLU(),
        lut_layer2
    )

    print("‚úÖ Full model built successfully")
    print(f"\nModel architecture:")
    print(model)

    # Test forward pass
    if torch.cuda.is_available():
        model = model.cuda()
        test_input = torch.randn(4, 128).cuda()
        output = model(test_input)
        print(f"\n‚úÖ Full model forward pass: input {test_input.shape} ‚Üí output {output.shape}")

except Exception as e:
    print(f"‚ùå Failed to build full model: {e}")
    import traceback
    traceback.print_exc()
    exit(1)

# ============================================================================
# SUMMARY
# ============================================================================
print("\n" + "=" * 70)
print("‚úÖ ALL TESTS PASSED!")
print("=" * 70)
print("\nFixed connections work perfectly with LUTLayer:")
print("  ‚úÖ Accepts torch.Tensor directly for mapping parameter")
print("  ‚úÖ Stores mapping as non-trainable parameter")
print("  ‚úÖ Preserves exact connection indices")
print("  ‚úÖ Connections stay fixed during training")
print("  ‚úÖ Works in full model architecture")
print("  ‚úÖ Forward pass produces correct output shapes")
print("\nüéØ Your current approach is optimal - no library changes needed!")
